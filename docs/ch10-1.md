# **10-1** Statistical Mechanics

<!-- TA office: AERB 430 -->

Before getting started with real plasma physics concepts, we need to quickly review some statistical mechanics with the goal of deriving the Maxwell-Boltzmann distribution.



As we all know, if we have \( N \) unique objects, there are \( N! \) ways of arranging them. If \( n_1 \ldots n_k \) are identical with N things, the number of combinations is 
$$
\frac{N!}{n_1 ! \ldots n_k !}
$$

What does probability have to do with a velocity distribution? Consider the one-dimensional random walk, in which we take \( N \) steps, and at each step we move in a random direction. We take \( n_r \) steps to the right and \( N - n_r \) steps to the left. For a random walk we assume the probability of going in each direction is the same
$$
P_r = p = \frac{1}{2} \qquad P_l = q =  \frac{1}{2}
$$
After taking \( N \)  steps, the probability of taking \( n_r \) steps to the right and \( (N - n_r) \) steps to the left is
$$
P(n_r) = \frac{N !}{n_r ! (N - n_r)!} \cdot p^{n_r} q^{n_r}
$$

We are also interested in the final destination, which is the net number of steps to the right
$$
m_r = n_r - n_l = 2 n_r - N
$$

If we have a bias to move in a particular direction, then \( p \neq q \) and the distribution \( P(n_r) \) will be shifted towards the bias.

Of course, if we have a very large \( N \) we aren't going to be able to compute \( P(n_r) \) directly. We've got our handy dandy natural logarithm to help us.

$$
\ln N! = \ln N + \ln (N - 1) + \ldots  + 1
$$

$$
\ln (N + 1) ! = \ln (N + 1) + \ln N!
$$

$$
\pdv{\ln N!}{N} \approx \frac{\ln(N+1)! - \ln N!}{N - (N-1)} = \ln(N+1) \approx \ln N
$$

Recall our expression for the probability distribution

$$
P(n_r) = \frac{N!}{n_r !(N - n_r)!} p^{n_r} q^{N- n_r}
$$
$$
\rightarrow \quad \ln P(n_r) = \ln N! - \ln n_r ! - \ln ((N-n_r)!) + n_r \ln p + (N - n_r) \ln q
$$

Now we apply the little log trick \( \pdv{\ln N!}{N} \approx \ln N \) 
$$
\dv{\ln P(n_r)}{n_r} = - \ln r + \ln (N - n_r) + \ln p - \ln q = 0
$$
$$
\qquad \rightarrow \qquad \ln \left( \frac{N - n_r}{n_r} \frac{p}{q} \right) = 0
$$
$$
(N - n_r)p = n_r q
$$
$$
Np = n_r(p + q) 
$$
$$
\overline{n_r} = Np
$$
Surprise surprise, the probability of getting a certain result is just the expectation value of that result. Can we also say anything about the width of the distribution? 
Taylor expand about \( \overline{n_r} = N p \) and define \( \eta \) by \( n_r = N p + \eta \) 
$$
\ln (P(n_r)) = \ln(P(Np)) + B_1 \eta + \frac{1}{2} B_2 \eta^2 + \frac{1}{6} B_3 \eta^4
$$
$$
B_k = \frac{d^k \ln P(n_r)}{d n_r ^k} 
$$
$$
\dv{\ln P(n_r)}{n_r} = - \ln n_r + \ln (N - n_r) + \ln p - \ln q
$$
$$
B_1 = - \ln(n_r) + \ln (N - n_r) + \ln p - \ln q
$$
$$
= - \ln (Np) + \ln(N - Np) = 0
$$
$$
B_2 = - \frac{1}{n_r} - \frac{1}{N - n_r} = - \frac{1}{Np} - \frac{1}{N - Np} = -\frac{1}{Nqp}
$$
$$
B_3 = \frac{1}{n_r ^2} - \frac{1}{(N - n_r)^2} \approx \frac{1}{N^2}
$$
$$
B_4 \approx \frac{1}{N_3}
$$

The expansion converges for \( N >> \eta \) 
$$
\ln(P(n_r)) \approx \ln (P(Np)) - \frac{1}{2} \frac{1}{Nqp} \eta ^2
$$
or
$$
P(n_r) = P(Np) e^{- \frac{\eta ^2}{2 Npq}} \qquad P_0 = P(Np)
$$
$$
P(\eta) = P_0 e^{-\frac{\eta ^2}{2Npq}}
$$

So what's the width?

$$
\langle \eta ^2 \rangle = \frac{ \int_{-\infty} ^\infty \eta ^2 P(\eta) \dd \eta }{\int_{-infty}^\infty P(\eta) \dd \eta} = \frac{ \frac{ \sqrt{\pi}}{4 \left( \frac{1}{2 N pq} \right) ^{3/2}}}{\frac{ \sqrt{\pi}}{2 \left( \frac{1}{2 N pq} \right)^{1/2}}} = \frac{2 Npq}{2} = Npq
$$

So the uncertainty is \( \delta n_r = \sqrt{ N pq} \approx \frac{1}{2} \sqrt{N} \). For a very large N, the relative uncertainty \( \delta n_r / N \approx \frac{1}{2 \sqrt{N}} \) diminishes and the distribution (centered at \( Np \) ) gets very narrow. The signal-to-noise will go as \( \frac{1}{\sqrt{N}} \).


## **10.1.2** Lagrange Multipliers

When we have a problem of variation where one function is maximized or minimized subject to a constraint imposed by another function

$$
f(x_1, \ldots x_n) \rightarrow \text{ function }
$$
$$
g(x_1, \ldots, x_n) = 0 \rightarrow \text { constraint }
$$

Without the constraint we would have the problem 
$$
\delta f = \pdv{f}{x_1} \delta x_1 + \ldots \pdv{f}{x_n} \delta x_n
$$
$$
\pdv{f}{x_i} = 0 \qquad i = 1 \ldots n
$$
and apply any of our multivariate optimization strategies to solve. This can be hard. Luckily, at any stationary point of the function that also satisfies the constraint, the gradient of the function at that point can be expressed as a linear combination of the gradients of the constraints at that point.

$$
\pdv{f}{x_i} - \lambda \pdv{g}{x_i} = 0
$$

With a constraint \( g = 0 \), the change in \( f \) becomes a change in the functional of \( f \) and \( g \).
$$
f, g \rightarrow h(f(x_1, \ldots, x_{n-1}), g(x_1, \ldots, x_{n-1})) = h(x_1, \ldots, x_{n-1}) = 0
$$
$$
\pdv{h}{x_i} \rightarrow i = 1 \rightarrow n-1
$$
At the stationary points we're looking for, 

Simplest example: Find the maximum area of a rectangle with perimeter \( 4a \)

$$
f = A = x_1 x_2
$$
$$
g = 0 = 2x_1 + 2x_2 - 4a
$$
$$
\delta f = x_2 \delta x_1 + x_1 \delta x_2
$$
$$
\lambda \delta g = \lambda 2 \delta x_1 + \lambda 2 \delta x_2
$$
$$
x_2 + 2\lambda = 0 \qquad x_1 + 2\lambda = 0
$$
$$
x_2 = - 2 \lambda \qquad x_1 = - 2 \lambda
$$
$$
\rightarrow - 4 \lambda - 4 \lambda - 4 a = 0 \rightarrow \lambda = - \frac{a}{2}
$$

## **10.1.3** Maxwell-Boltzmann Distribution Function

Suppose we've got a large number N of particles with total energy \( W \). What is the energy distribution among the particles?

We call a "state" a possible distribution (permutation) of energy among the particles which satisfies the constraints.  The fundamental principle of statistical mechanics states that all states have an equal chance of being occupied, with the resulting combinatorial factor giving the distribution. Because the number of particles is very large, the distribution will be close to the distribution that has the largest number of states.

Label the particles by the energy they have. Let \( n_i \) be the number of particles with energy between \( \epsilon_i \) and \( \epsilon_{i+1} = \epsilon_i + \delta \epsilon \). Choose \( k \) different energy ranges:

$$
\sum_{i = 0} ^k n_i = N \qquad \sum_{i=1} ^k \epsilon_i n_i = W = \text{ total energy}
$$ 

The number of states with a given distribution is just a partitioning (indistinguishable!) of the energy among \( k \) bins, so

$$
P = \frac{1}{N} \frac{N!}{n_1 ! \ldots n_k ! } = \frac{N-1!}{n_1 ! \ldots n_k ! } \approx \frac{N!}{n_1 ! \ldots n_k ! }
$$

We know that the distribution will be closely centered about the maximum of P, subject to the conservation constraints of energy and particles

$$
\delta N = 0 = \sum _1 ^ k \delta n_i
$$

$$
\delta W = 0 = \sum_1 ^k \epsilon_i \delta n_i 
$$

Going back to our log trick to find the critical point
$$
\delta \ln P = 0
$$
$$
\ln P = \ln N! - \sum_1 ^k \ln n_i !
$$
$$
\delta \ln P = - \sum_1 ^k \ln n_i \delta n_i = 0
$$

Let \( \lambda \)  be the Lagrange multiplier for \( \delta N \) and \( \beta \) be the Lagrange multiplier for \( \delta W \), so

$$
(\ln n_i + \lambda + \beta \epsilon_i) \delta n_i = 0
$$
$$
\ln n_i = 0 \lambda - \beta \epsilon_i
$$
$$
n_i = e^{-\lambda - \beta \epsilon_i} = n_\lambda e^{-\beta \epsilon_i}
$$
Values of \( n_\lambda \) just come from the real constraints \( N \)  and \( W \) 

$$
\int _0 ^\infty n_\lambda e^{- \beta \epsilon} \dd \epsilon = N
$$
$$
\int_0 ^\infty \epsilon n_\lambda e^{- \beta \epsilon} \dd \epsilon = W
$$

Putting in our constraints, out pops the Maxwell-Boltzmann distribution

$$
f(\vec v) \dd \vec v = n \left( \frac{m}{2 \pi k T} \right) ^{3/2} e^{- \epsilon / kT} \qquad \epsilon = \text{ KE + PE }
$$

!!! question "Example: Distribution under Gravity"

    If we have a bunch of particles under the influence of gravity, the energy is
    $$
    \epsilon = \frac{1}{2} m v^2 + mgz
    $$
    The distribution is
    $$
    f(v) = n_0 \left( \frac{m}{2 \pi k T} \right) ^{3/2} e^{-( \frac{1}{2} m v^2 + mgz)/kT}
    $$
    $$
    = n(z) \left( \frac{m}{2 \pi k T} \right) ^{3/2} e^{-\frac{1}{2} m v^2 / kT}
    $$
    $$
    n(z) = n_0 e^{- mgz / kT}
    $$
    In a collisionless picture, the velocity spread is the same at all heights (\( kT \) is not a function of z). However lower energy particles do not make it to a higher z. We end up with a density drop with increasing \( z \) .